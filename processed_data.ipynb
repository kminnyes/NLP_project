{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueFoQEmWw8KH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "z199rqt_xh9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "yRBwBq4HxkLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_paths = [\n",
        "    \"/content/drive/MyDrive/Training-20241214T060301Z-001/Training/talksets-train-1.json\",\n",
        "    \"/content/drive/MyDrive/Training-20241214T060301Z-001/Training/talksets-train-2.json\",\n",
        "    \"/content/drive/MyDrive/Training-20241214T060301Z-001/Training/talksets-train-3.json\",\n",
        "    \"/content/drive/MyDrive/Training-20241214T060301Z-001/Training/talksets-train-4.json\",\n",
        "    \"/content/drive/MyDrive/Training-20241214T060301Z-001/Training/talksets-train-5.json\"\n",
        "]"
      ],
      "metadata": {
        "id": "rA_BFc9Bxq_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 전처리(불용어 제거)\n",
        "def preprocess_text(text):\n",
        "  text = re.sub(r\"[ㅋㅎㅠㅜ]+\", \"\", text)\n",
        "  if re.search(r\"[#@]\", text):\n",
        "    return None\n",
        "  return text.strip()"
      ],
      "metadata": {
        "id": "c0uoLxVXx0YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 파일 구조 확인\n",
        "with open(file_paths[0], \"r\", encoding=\"utf-8\") as file:\n",
        "    data = json.load(file)\n",
        "    print(data)"
      ],
      "metadata": {
        "id": "mzoi5A3mx2Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 파일 로드 및 병합\n",
        "all_sentences = []\n",
        "\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "        if isinstance(data, list):\n",
        "            all_sentences.extend(data)\n",
        "        elif isinstance(data, dict) and \"sentences\" in data:\n",
        "            all_sentences.extend(data[\"sentences\"])\n",
        "\n",
        "print(f\"총 로드된 데이터 개수: {len(all_sentences)}\")"
      ],
      "metadata": {
        "id": "1SWKudq-x3ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 및 형태 변환\n",
        "processed_data = []\n",
        "\n",
        "for item in all_sentences:\n",
        "    if \"sentences\" not in item:\n",
        "        continue\n",
        "\n",
        "    for sentence in item[\"sentences\"]:\n",
        "        if \"text\" not in sentence or \"is_immoral\" not in sentence or \"intensity\" not in sentence:\n",
        "            continue\n",
        "\n",
        "        cleaned_text = preprocess_text(sentence[\"text\"])\n",
        "\n",
        "        if cleaned_text is None:\n",
        "            continue\n",
        "\n",
        "        # 필요한 데이터만 추출\n",
        "        processed_item = {\n",
        "            \"text\": cleaned_text,\n",
        "            \"is_immoral\": sentence[\"is_immoral\"],\n",
        "            \"intensity\": sentence[\"intensity\"]\n",
        "        }\n",
        "        processed_data.append(processed_item)\n",
        "\n",
        "print(f\"전처리된 데이터 개수: {len(processed_data)}\")"
      ],
      "metadata": {
        "id": "BiCkvaQByCnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# intensity 구간별로 데이터를 나눔\n",
        "intensity_1 = [item for item in processed_data if 1.0 <= item[\"intensity\"] <= 1.9]\n",
        "intensity_2 = [item for item in processed_data if 2.0 <= item[\"intensity\"] <= 2.9]\n",
        "intensity_3 = [item for item in processed_data if item[\"intensity\"] > 2.9]\n",
        "\n",
        "# 총 데이터 50000개로 축소\n",
        "target_size = 50000\n",
        "\n",
        "# 각 구간의 목표 개수\n",
        "size_1 = int(target_size * 0.4)  # 40%\n",
        "size_2 = int(target_size * 0.3)  # 30%\n",
        "size_3 = target_size - size_1 - size_2  # 나머지 (30%)\n",
        "\n",
        "# 각 구간에서 샘플링\n",
        "sampled_1 = random.sample(intensity_1, min(size_1, len(intensity_1)))\n",
        "sampled_2 = random.sample(intensity_2, min(size_2, len(intensity_2)))\n",
        "sampled_3 = random.sample(intensity_3, min(size_3, len(intensity_3)))\n",
        "\n",
        "filtered_data = sampled_1 + sampled_2 + sampled_3\n",
        "\n",
        "# 섞기\n",
        "random.shuffle(filtered_data)\n",
        "\n",
        "print(f\"intensity 1.0 ~ <2.0: {len(sampled_1)}개\")\n",
        "print(f\"intensity 2.0 ~ 2.9: {len(sampled_2)}개\")\n",
        "print(f\"intensity >2.9: {len(sampled_3)}개\")\n",
        "print(f\"최종 데이터 개수: {len(filtered_data)}\")"
      ],
      "metadata": {
        "id": "OnWNk1pOyIFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 항목 출력\n",
        "if len(processed_data) > 0:\n",
        "    print(\"첫 번째 항목:\")\n",
        "    print(json.dumps(processed_data[0], indent=4, ensure_ascii=False))\n",
        "else:\n",
        "    print(\"processed_data가 비어 있습니다. 데이터를 확인하세요!\")"
      ],
      "metadata": {
        "id": "81QnDPvLyk1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"/content/drive/MyDrive/processed_training_50000_data.json\"\n",
        "\n",
        "# 변환된 데이터 저장\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
        "    json.dump(filtered_data, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"전처리 및 병합된 데이터가 저장되었습니다: {output_path}\")"
      ],
      "metadata": {
        "id": "Yg-yTEHm0x_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3c1qQbGP0_ef"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}