{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qgi0RHNAOF-9"
      },
      "outputs": [],
      "source": [
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "import json\n",
        "\n",
        "# 데이터 경로 설정 (Google Drive에서 JSON 파일 경로 지정)\n",
        "file_path = '/content/drive/MyDrive/small_dataset.json'\n",
        "\n",
        "# JSON 데이터 읽기\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# 데이터 확인\n",
        "print(f\"데이터 개수: {len(dataset)}\")\n",
        "print(dataset[:3])"
      ],
      "metadata": {
        "id": "pFSe6P-uO3uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertModel\n",
        "\n",
        "# 사용자 정의 KoBERT 클래스\n",
        "class CustomKoBERT(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomKoBERT, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"monologg/kobert\")  # KoBERT 모델\n",
        "        self.fc_is_immoral = torch.nn.Linear(768, 1)  # 비도덕성 여부 출력 (1개)\n",
        "        self.fc_intensity = torch.nn.Linear(768, 1)  # 강도 출력 (1개)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs[1]  # [CLS] 토큰에 대한 출력\n",
        "        is_immoral = torch.sigmoid(self.fc_is_immoral(pooled_output))  # 비도덕성 확률\n",
        "        intensity = torch.sigmoid(self.fc_intensity(pooled_output)) * 3  # 강도 (1.0 ~ 3.0)\n",
        "        return is_immoral, intensity"
      ],
      "metadata": {
        "id": "_K2Kvoz1Po6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 정의 KoBERT 초기화\n",
        "kobert_model = CustomKoBERT()\n",
        "\n",
        "# Google Drive에서 학습된 가중치 로드\n",
        "kobert_model_path = \"/content/drive/MyDrive/kobert_model.pth\"\n",
        "kobert_model.load_state_dict(torch.load(kobert_model_path, map_location=torch.device('cpu')))\n",
        "\n",
        "# 평가 모드 설정\n",
        "kobert_model.eval()\n",
        "print(\"학습된 KoBERT 모델이 성공적으로 로드되었습니다.\")"
      ],
      "metadata": {
        "id": "Y-xlRDuZPtky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# KoBERT 토크나이저 로드\n",
        "tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\")\n",
        "\n",
        "# KoBERT로 강도와 비도덕성 판단\n",
        "def predict_immorality_and_intensity(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        is_immoral, intensity_score = kobert_model(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
        "    is_immoral = is_immoral.item() > 0.5  # 비도덕성 여부\n",
        "    intensity_score = intensity_score.item()  # 강도 점수 (1.0 ~ 3.0)\n",
        "    return is_immoral, intensity_score\n",
        "\n",
        "# 테스트\n",
        "test_text = \"너 정말 재수없다.\"\n",
        "is_immoral, intensity_score = predict_immorality_and_intensity(test_text)\n",
        "print(f\"입력 텍스트: {test_text}\")\n",
        "print(f\"비도덕성 여부: {is_immoral}, 강도 점수: {intensity_score:.2f}\")"
      ],
      "metadata": {
        "id": "TrLdgaT1PIsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 강도별 응답 정의\n",
        "responses = {\n",
        "    \"low\": [\n",
        "        \"그렇게 생각할 수도 있군요. 하지만 조금 더 긍정적으로 생각해보는 건 어때요?\",\n",
        "        \"당신의 의견을 존중하지만, 그런 말을 조심하는 게 좋을 것 같아요.\"\n",
        "    ],\n",
        "    \"medium\": [\n",
        "        \"그런 표현은 적절하지 않을 수 있어요. 조금 더 신중하게 생각해 주세요.\",\n",
        "        \"그 말은 조금 기분 나쁘게 들려요. 다른 사람이 불쾌감을 느낄 수 있는 표현은 피해 주세요.\"\n",
        "    ],\n",
        "    \"high\": [\n",
        "        \"그런 말은 너무 불쾌합니다. 사과해주세요.\",\n",
        "        \"당신은 너무 무례합니다. 예의를 갖추세요.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 강도 레이블 계산 함수\n",
        "def get_intensity_label(intensity_score):\n",
        "    if intensity_score <= 1.9:\n",
        "        return \"low\"\n",
        "    elif 2.0 <= intensity_score <= 2.9:\n",
        "        return \"medium\"\n",
        "    else:\n",
        "        return \"high\""
      ],
      "metadata": {
        "id": "KJRnG_l4PNAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KoBERT와 통합된 응답 생성 함수\n",
        "def generate_response_from_kobert(text):\n",
        "    is_immoral, intensity_score = predict_immorality_and_intensity(text)\n",
        "\n",
        "    if not is_immoral:  # 비도덕적이지 않다면\n",
        "        return \"그런 표현은 비도덕적이지 않습니다.\"\n",
        "\n",
        "    # 강도 레이블 계산\n",
        "    intensity_label = get_intensity_label(intensity_score)\n",
        "\n",
        "    # 강도별 응답 선택\n",
        "    return responses[intensity_label][0]"
      ],
      "metadata": {
        "id": "1bD-6MRSQjtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# KoGPT2 모델 로드\n",
        "generator = pipeline(\"text-generation\", model=\"skt/kogpt2-base-v2\")\n",
        "\n",
        "# Few-shot Prompt 작성\n",
        "def few_shot_prompt(input_text, intensity_label):\n",
        "    prompt = f\"\"\"\n",
        "다음은 비도덕적인 표현에 대한 적절한 응답 예시입니다.\n",
        "\n",
        "사용자: 너는 항상 실수만 하는구나.\n",
        "강도: low\n",
        "KoGPT2의 응답: 그렇게 느껴질 수도 있겠네요. 하지만 발전을 위해 노력하고 있어요\n",
        "\n",
        "사용자: 니가 뭘 안다고 나대냐?\n",
        "강도: medium\n",
        "KoGPT2의 응답: 그런 표현은 부적절합니다. 차분히 이야기해 주세요.\n",
        "\n",
        "사용자: 고객 응대도 못하는 버러지 새끼가 무슨 장사를 한다고 설쳐?\n",
        "강도: high\n",
        "KoGPT2의 응답: 그런 말은 너무 불쾌합니다. 사과해주세요.\n",
        "\n",
        "KoGPT2의 응답:\"\"\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "Hj2VJVJWTNhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KoGPT2 응답 생성 및 처리\n",
        "def generate_gpt2_response(prompt):\n",
        "    response = generator(prompt, max_new_tokens=50, num_return_sequences=1)\n",
        "    generated_text = response[0]['generated_text']\n",
        "\n",
        "    # \"KoGPT2의 응답:\" 이후 텍스트만 추출\n",
        "    if \"KoGPT2의 응답:\" in generated_text:\n",
        "        response_text = generated_text.split(\"KoGPT2의 응답:\")[1].strip()\n",
        "    else:\n",
        "        response_text = generated_text.strip()\n",
        "\n",
        "    # 두 문장으로 제한\n",
        "    final_response = limit_to_two_sentences(response_text)\n",
        "    return final_response\n",
        "\n",
        "# KoGPT2 응답을 두 문장으로 제한\n",
        "def limit_to_two_sentences(response):\n",
        "    sentences = response.split(\".\")  # \".\" 기준으로 분리\n",
        "    limited_response = \".\".join(sentences[:2]).strip() + \".\"  # 두 문장까지 연결\n",
        "    return limited_response"
      ],
      "metadata": {
        "id": "fOdnk6SOU5Ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rule-Based와 KoGPT2 응답 통합\n",
        "def generate_combined_response(input_text, intensity_label):\n",
        "    # Rule-Based 응답 생성\n",
        "    rule_based_response = generate_rule_based_response(intensity_label)\n",
        "\n",
        "    # Few-shot Prompt 작성\n",
        "    prompt = few_shot_prompt(input_text, intensity_label)\n",
        "\n",
        "    # KoGPT2 응답 생성\n",
        "    try:\n",
        "        gpt2_response = generate_gpt2_response(prompt)\n",
        "    except Exception as e:\n",
        "        print(f\"KoGPT2 응답 생성 실패: {e}\")\n",
        "        return rule_based_response  # 실패 시 Rule-Based 응답 반환\n",
        "\n",
        "    # Rule-Based 응답과 KoGPT2 응답 결합\n",
        "    combined_response = f\"{rule_based_response} 추가적으로, {gpt2_response}\"\n",
        "    return combined_response"
      ],
      "metadata": {
        "id": "nHIy-wGZbmrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 입력\n",
        "test_input = \"너 정말 무례하다.\"\n",
        "\n",
        "# KoBERT로 비도덕성과 강도 판단\n",
        "is_immoral, intensity_score = predict_immorality_and_intensity(test_input)\n",
        "print(f\"입력 텍스트: {test_input}\")\n",
        "print(f\"비도덕성 여부: {is_immoral}, 강도 점수: {intensity_score:.2f}\")\n",
        "\n",
        "if is_immoral:\n",
        "    # 강도 레이블 계산\n",
        "    intensity_label = get_intensity_label(intensity_score)\n",
        "\n",
        "    # Prompt 생성\n",
        "    dynamic_prompt = few_shot_prompt(test_input, intensity_label)\n",
        "\n",
        "    # KoGPT2 응답 생성\n",
        "    final_response = generate_gpt2_response(dynamic_prompt)\n",
        "    print(f\"생성된 응답:\\n{final_response}\")\n",
        "else:\n",
        "    print(\"그런 표현은 비도덕적이지 않습니다.\")"
      ],
      "metadata": {
        "id": "i1XT3SIcQlzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NCBXf4_wA58z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}