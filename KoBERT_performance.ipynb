{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJjx-iYqOJ4e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMjKV6ThOhKN"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYlCKrm9Orzi"
   },
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "model_path = \"/content/drive/MyDrive/koBERT_model/kobert_model.pth\"\n",
    "data_path = \"/content/drive/MyDrive/validation_immoral.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6VKKAPpO9pP"
   },
   "outputs": [],
   "source": [
    "# Dataset 클래스 정의\n",
    "class KoBERTDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'is_immoral': torch.tensor(label[\"is_immoral\"], dtype=torch.float),\n",
    "            'intensity': torch.tensor(label[\"intensity\"], dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnkqtIGWPBRs"
   },
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class CustomKoBERT(torch.nn.Module):\n",
    "    def __init__(self, bert_model_name):\n",
    "        super(CustomKoBERT, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.fc_is_immoral = torch.nn.Linear(768, 1)\n",
    "        self.fc_intensity = torch.nn.Linear(768, 1)  # 강도\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        is_immoral = self.fc_is_immoral(pooled_output).squeeze(-1)\n",
    "        intensity = self.fc_intensity(pooled_output).squeeze(-1)\n",
    "        intensity = 1 + 2 * torch.sigmoid(intensity)  # 강도를 1~3 범위로 제한\n",
    "        return is_immoral, intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnX7YopkPFI5"
   },
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomKoBERT(\"monologg/kobert\")\n",
    "\n",
    "# .pth 파일 로드\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GA0GudqhPH9M"
   },
   "outputs": [],
   "source": [
    "# Validation 데이터 로드\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    validation_data = json.load(file)\n",
    "\n",
    "texts = [item['text'] for item in validation_data]\n",
    "labels = [\n",
    "    {\n",
    "        \"is_immoral\": 1 if item['is_immoral'] else 0,\n",
    "        \"intensity\": 0 if not item['is_immoral'] else max(1, min(3, item['intensity'])),  # is_immoral=0인 경우 intensity=0\n",
    "    }\n",
    "    for item in validation_data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UolRpTkuPP6w"
   },
   "outputs": [],
   "source": [
    "# `max_len` 및 `batch_size` 정의\n",
    "max_len = 64\n",
    "batch_size = 16\n",
    "\n",
    "validation_dataset = KoBERTDataset(\n",
    "    texts,\n",
    "    labels,\n",
    "    tokenizer=BertTokenizer.from_pretrained(\"monologg/kobert\"),\n",
    "    max_len=max_len\n",
    ")\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hE_I54vgPTEI"
   },
   "outputs": [],
   "source": [
    "# 평가 함수\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    preds_is_immoral = []\n",
    "    preds_intensity = []\n",
    "    true_is_immoral = []\n",
    "    true_intensity = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            true_is_immoral_batch = batch['is_immoral'].to(device)\n",
    "            true_intensity_batch = batch['intensity'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            is_immoral, intensity = model(input_ids, attention_mask)\n",
    "\n",
    "            # Predictions\n",
    "            preds_is_immoral.extend((is_immoral > 0).long().cpu().numpy())\n",
    "            preds_intensity.extend(intensity.cpu().numpy())\n",
    "\n",
    "            # True labels\n",
    "            true_is_immoral.extend(true_is_immoral_batch.long().cpu().numpy())\n",
    "            true_intensity.extend(true_intensity_batch.cpu().numpy())\n",
    "\n",
    "    return (\n",
    "        np.array(preds_is_immoral), np.array(preds_intensity),\n",
    "        np.array(true_is_immoral), np.array(true_intensity)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFNJuCl7PXl5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "errors = np.abs(true_intensity - preds_intensity)\n",
    "\n",
    "tolerance = 1.0  # 허용 오차 범위\n",
    "\n",
    "accurate_predictions = (errors <= tolerance).sum()\n",
    "total_predictions = len(errors)\n",
    "accuracy = accurate_predictions / total_predictions\n",
    "\n",
    "# MSE와 MAE\n",
    "mse = mean_squared_error(true_intensity, preds_intensity)\n",
    "mae = mean_absolute_error(true_intensity, preds_intensity)\n",
    "\n",
    "print(f\"전체 데이터에서 허용 오차(±{tolerance}) 내에서 정확히 예측한 비율: {accuracy * 100:.2f}%\")\n",
    "print(f\"전체 데이터의 Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"전체 데이터의 Mean Absolute Error (MAE): {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgPqhr6nwgJZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
